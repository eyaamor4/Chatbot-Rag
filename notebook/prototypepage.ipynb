{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5f414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import psycopg\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248b2056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration PostgreSQL charg√©e ‚úîÔ∏è\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"../src/.env\")\n",
    "\n",
    "db_connection_str = (\n",
    "    f\"dbname={os.getenv('DB_NAME')} \"\n",
    "    f\"user={os.getenv('DB_USER')} \"\n",
    "    f\"password={os.getenv('DB_PASSWORD')} \"\n",
    "    f\"host={os.getenv('DB_HOST')} \"\n",
    "    f\"port={os.getenv('DB_PORT')}\"\n",
    ")\n",
    "\n",
    "print(\"Configuration PostgreSQL charg√©e ‚úîÔ∏è\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37905ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes charg√©es : 1062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['h: U B S bonjour',\n",
       " \"c: oui bonjour e j'appelle je sais pas si j'appelle au bon endroit e\",\n",
       " 'h: je vous √©coute',\n",
       " \"c: c'est pour\",\n",
       " \"c: e c'est pour savoir si la fac pendant l'√©t√© e a des professeurs ou des des gens qui font des stages de de perfectionnement en anglais et en espagnol\",\n",
       " 'h: e ce serait pour vous vous souhaiteriez',\n",
       " 'h: non',\n",
       " \"c: non non c'est pas pour moi\",\n",
       " 'c: ce serait pour ma fille',\n",
       " 'h: oui']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "def load_all_transcripts(folder_path: str) -> List[str]:\n",
    "    corpus_list = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    lines = f.read().split(\"\\n\")\n",
    "            except:\n",
    "                with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                    lines = f.read().split(\"\\n\")\n",
    "\n",
    "            cleaned = [\n",
    "                l.strip()\n",
    "                for l in lines\n",
    "                if l.strip() != \"\" and not l.startswith(\"<\")\n",
    "            ]\n",
    "\n",
    "            corpus_list.extend(cleaned)\n",
    "\n",
    "    return corpus_list\n",
    "\n",
    "\n",
    "conversation_folder = \"../data/TRANS_TXT/\"\n",
    "corpus_list = load_all_transcripts(conversation_folder)\n",
    "\n",
    "print(\"Nombre total de lignes charg√©es :\", len(corpus_list))\n",
    "corpus_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381e6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def calculate_embeddings_ollama(text: str, model: str = \"mxbai-embed-large\") -> List[float]:\n",
    "    response = ollama.embeddings(\n",
    "        model=model,\n",
    "        prompt=text\n",
    "    )\n",
    "    return response[\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95830ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3945574462413788,\n",
       " -0.1477288007736206,\n",
       " -0.7611244916915894,\n",
       " 0.31378623843193054,\n",
       " -0.38164928555488586,\n",
       " -0.12771975994110107,\n",
       " 0.6281507611274719,\n",
       " 0.27708899974823,\n",
       " 0.23378583788871765,\n",
       " 0.36259424686431885]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "calculate_embeddings_ollama(\"bonjour\")[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ec0924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect√© √† PostgreSQL : rag_chatbot\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg.connect(db_connection_str)\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Connect√© √† PostgreSQL :\", conn.info.dbname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da65dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table embeddings recr√©√©e avec VECTOR(1024) ‚úîÔ∏è\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS embeddings;\")\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE embeddings (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        corpus TEXT,\n",
    "        embedding vector(1024)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"Table embeddings recr√©√©e avec VECTOR(1024) ‚úîÔ∏è\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3548120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lignes ins√©r√©es‚Ä¶\n",
      "50 lignes ins√©r√©es‚Ä¶\n",
      "100 lignes ins√©r√©es‚Ä¶\n",
      "150 lignes ins√©r√©es‚Ä¶\n",
      "200 lignes ins√©r√©es‚Ä¶\n",
      "250 lignes ins√©r√©es‚Ä¶\n",
      "300 lignes ins√©r√©es‚Ä¶\n",
      "350 lignes ins√©r√©es‚Ä¶\n",
      "400 lignes ins√©r√©es‚Ä¶\n",
      "450 lignes ins√©r√©es‚Ä¶\n",
      "500 lignes ins√©r√©es‚Ä¶\n",
      "550 lignes ins√©r√©es‚Ä¶\n",
      "600 lignes ins√©r√©es‚Ä¶\n",
      "650 lignes ins√©r√©es‚Ä¶\n",
      "700 lignes ins√©r√©es‚Ä¶\n",
      "750 lignes ins√©r√©es‚Ä¶\n",
      "800 lignes ins√©r√©es‚Ä¶\n",
      "850 lignes ins√©r√©es‚Ä¶\n",
      "900 lignes ins√©r√©es‚Ä¶\n",
      "950 lignes ins√©r√©es‚Ä¶\n",
      "1000 lignes ins√©r√©es‚Ä¶\n",
      "1050 lignes ins√©r√©es‚Ä¶\n",
      "üéâ Tous les embeddings ont √©t√© ins√©r√©s avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "def save_embedding(cursor, corpus: str, embedding: List[float]):\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO embeddings (corpus, embedding) VALUES (%s, %s)\",\n",
    "        (corpus, embedding)\n",
    "    )\n",
    "\n",
    "for i, text in enumerate(corpus_list):\n",
    "    emb = calculate_embeddings_ollama(text)  # maintenant mxbai-embed-large (1024)\n",
    "    save_embedding(cur, text, emb)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{i} lignes ins√©r√©es‚Ä¶\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"üéâ Tous les embeddings ont √©t√© ins√©r√©s avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb26751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pgvector(x: List[float]) -> str:\n",
    "    return \"[\" + \", \".join(str(v) for v in x) + \"]\"\n",
    "\n",
    "def search_similar(text: str, k: int = 15):\n",
    "    emb = calculate_embeddings_ollama(text)\n",
    "    emb_vec = to_pgvector(emb)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT id, corpus, embedding <-> %s AS distance\n",
    "        FROM embeddings\n",
    "        ORDER BY distance ASC\n",
    "        LIMIT %s;\n",
    "    \"\"\", (emb_vec, k))\n",
    "\n",
    "    return cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc5a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction PostgreSQL r√©initialis√©e ‚úîÔ∏è\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "print(\"Transaction PostgreSQL r√©initialis√©e ‚úîÔ∏è\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974ac7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 235\n",
      "Texte: c: e c'est ouvert aujourd'hui par exemple\n",
      "Distance: 13.069447399269245\n",
      "---\n",
      "ID: 237\n",
      "Texte: c: aujourd'hui c'est ouvert par exemple\n",
      "Distance: 13.627479257660557\n",
      "---\n",
      "ID: 662\n",
      "Texte: c: e il doit y avoir des supports non\n",
      "Distance: 14.001935552585222\n",
      "---\n",
      "ID: 714\n",
      "Texte: c: dans un instant peut √™tre\n",
      "Distance: 14.07545735512205\n",
      "---\n",
      "ID: 1007\n",
      "Texte: c: ah pas cette\n",
      "Distance: 14.116770279529238\n",
      "---\n",
      "ID: 317\n",
      "Texte: c: et de tout √ßa\n",
      "Distance: 14.163723149892364\n",
      "---\n",
      "ID: 83\n",
      "Texte: c: √† l'accueil\n",
      "Distance: 14.1980575737383\n",
      "---\n",
      "ID: 608\n",
      "Texte: c: il r√©pond pas\n",
      "Distance: 14.258205260001278\n",
      "---\n",
      "ID: 17\n",
      "Texte: h: oui alors e la fac de e de lettre et de langues se trouve √† Lorient donc il faudrait plut√¥t  voir avec Lorient pour e savoir si ils organisent des stages mais en tout cas fac est ferm√©e du 23 juillet au 23 ao√ªt\n",
      "Distance: 14.261680768060899\n",
      "---\n",
      "ID: 21\n",
      "Texte: c: un organisme sur Vannes qui qui s'occupe de ce genre de chose\n",
      "Distance: 14.316190418734614\n",
      "---\n",
      "ID: 1041\n",
      "Texte: c: et je voulais savoir ben d'une part s'il √©tait bien parvenu et\n",
      "Distance: 14.381848105568373\n",
      "---\n",
      "ID: 684\n",
      "Texte: c: √† l'ADEFOP\n",
      "Distance: 14.461451360062487\n",
      "---\n",
      "ID: 673\n",
      "Texte: c: √† l'ext√©rieur ou quelque chose comme √ßa\n",
      "Distance: 14.479262683284757\n",
      "---\n",
      "ID: 609\n",
      "Texte: h: non ben il doit pas √™tre\n",
      "Distance: 14.616259971073044\n",
      "---\n",
      "ID: 963\n",
      "Texte: c: s'il peut\n",
      "Distance: 14.642716591190375\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "query = \"Est-ce que la fac est ouverte pendant l'√©t√© ?\"\n",
    "results = search_similar(query, k=15)\n",
    "\n",
    "for r in results:\n",
    "    print(\"ID:\", r[0])\n",
    "    print(\"Texte:\", r[1])\n",
    "    print(\"Distance:\", r[2])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba8b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question: str, retrieved_texts: List[str]) -> str:\n",
    "    context = \"\\n---\\n\".join(retrieved_texts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Tu es un assistant STRICTEMENT bas√© sur les documents.\n",
    "\n",
    "R√àGLES IMPORTANTES :\n",
    "- Tu NE DOIS JAMAIS inventer d‚Äôinformation.\n",
    "- Si la r√©ponse n‚Äôest pas explicitement dans le contexte,\n",
    "  tu DOIS r√©pondre : \"Information insuffisante dans le corpus.\"\n",
    "\n",
    "DOCUMENTS :\n",
    "{context}\n",
    "\n",
    "QUESTION :\n",
    "{question}\n",
    "\n",
    "R√âPONSE (sans rien inventer) :\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.generate(model=\"llama3.1:latest\", prompt=prompt)\n",
    "    return response[\"response\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0db7d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION : Est-ce que l‚Äôaccueil peut transf√©rer un appel vers le secr√©tariat ?\n",
      "DOCUMENTS UTILIS√âS : [\"c: √† l'accueil\", \"h: si si mais √† l'accueil\", \"c: d'accord je rappelle √† l'accueil ok merci\", \"h: ouais ouais ouais ben e et a dix si il y a personne √† l'accueil elle va directement au secr√©tariat\", \"h: ah oui c'est retomb√© √† l'accueil\", 'c: e donc e s(oit) soit adjoint administratif ou r√©dacteur e', 'h: e oui je vais vous passer le secr√©tariat', \"h: voil√† c'est le Service Universitaire de l'Information et de l'Orientation parce que ici vous √™tes √† l'accueil de la fac de droit donc e\", 'h: concern√©e donc secr√©tariat', 'h: √ßa va la connexion va r√©(ouvir) se r√©ouvrir √† la e pour la val(idation) pour le e la confirmation du bac', \"c: est-ce qu'il y a une ligne directe pour le son service\", 'c: e il travaille e au niveau informatique', \"c: e oui bonjour j'aurais souhait√© avoir le secr√©tariat de du D U e carri√®re juridique s'il vous plait\", 'h: e attendez si elle est dans son bureau l√† elle vient de rentrer', \"h: oui je vais regarder s'il est dans son bureau ou au secr√©tariat\", 'h: vous pouvez me dire le bureau ou alors e']\n",
      "\n",
      "R√âPONSE DU MOD√àLE :\n",
      " Oui. \n",
      "\n",
      "Dans le document \"h: ouais ouais ouais ben e et a dix si il y a personne √† l'accueil elle va directement au secr√©tariat\" on peut lire : \"elle va directement au secr√©tariat\".\n",
      "\n",
      "Il est donc mentionn√© explicitement que l'accueil peut transf√©rer un appel vers le secr√©tariat.\n"
     ]
    }
   ],
   "source": [
    "question = \"Est-ce que l‚Äôaccueil peut transf√©rer un appel vers le secr√©tariat ?\"\n",
    "\n",
    "\n",
    "top_docs = [r[1] for r in search_similar(question, 16)]\n",
    "\n",
    "# g√©n√©rer la r√©ponse\n",
    "answer = generate_answer(question, top_docs)\n",
    "\n",
    "print(\"QUESTION :\", question)\n",
    "print(\"DOCUMENTS UTILIS√âS :\", top_docs)\n",
    "print(\"\\nR√âPONSE DU MOD√àLE :\\n\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.8.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
